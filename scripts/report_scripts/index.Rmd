---
title: "SARS-CoV-2 Wastewater Sampling Reports"
nav: "Overview"
author: "BIMSB Bioinformatics Platform"
date: '`r format(as.POSIXct(if ("" != Sys.getenv("SOURCE_DATE_EPOCH")) { as.numeric(Sys.getenv("SOURCE_DATE_EPOCH")) } else { Sys.time() }, origin="1970-01-01"), "%Y-%m-%d %H:%M:%S")`'
params:
  variants_csv: ""
  mutations_csv: ""
  sample_sheet: ""
  mutation_sheet: ""
  mutation_coverage_threshold: ""
  logo: ""
  fun_tbls: ""
  output_dir: ""
  overviewQC: ""
  fun_cvrg_scr: ""
  fun_pool: ""
  fun_index: ""
  unfiltered_mutation_sig_file: ""
  mut_count_file: ""
---

<style>
.pigx_info {
  background-image: url(params$logo);
}

.notice {
  margin-left: -12px;
  padding-left: 6px;
  border-left: 6px solid #ff9999;
}
.dropdown-menu {
  max-height: 200px;
  overflow-y: scroll;}

</style>

<div id="logo" align="top">
`r knitr::include_graphics(params$logo)`
</div>

```{r knitr_chunk_options, message=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r alerts}
# you may trigger these formatted notifications by enabling the corresponding
# settings in the respective chunk:
# error --> error=TRUE
# warning --> warning=TRUE
# message --> message=TRUE

# format error, warning and messages with html styles
# https://selbydavid.com/vignettes/alerts.html
knitr::knit_hooks$set(
  error = function(x, options) {
    paste('\n\n<div class="alert alert-danger">',
      gsub("^##", "\n", gsub("^##\ Error", "**Error**", x)),
      "</div>",
      sep = "\n"
    )
  },
  warning = function(x, options) {
    paste('\n\n<div class="alert alert-warning">',
      gsub("##", "\n", gsub("^##\ Warning:", "**Warning**", x)),
      "</div>",
      sep = "\n"
    )
  },
  message = function(x, options) {
    paste('\n\n<div class="alert alert-info">',
      gsub("##", "\n", x),
      "</div>",
      sep = "\n"
    )
  }
)
```

```{r libraries}
library(data.table)
library(plotly)
library(htmltools)
library(reshape2)
library(base64url)
library(DT)
library(data.table)
library(stringr)
library(ggplot2)
library(dplyr)
library(viridis)
```

```{r input}
# TODO given as input? or only the scripts dir? similar variant_report
source(params$fun_pool)
source(params$fun_index)

mutations_sig_unfiltered <- fread(params$unfiltered_mutation_sig_file)

df_var <- fread(params$variants_csv)
df_mut <- fread(params$mutations_csv)

mut_str_sep <- ":"
```

```{r format_threshold}
mutation_coverage_threshold <- params$mutation_coverage_threshold %>%
  # check if value is given as fraction [0,1] or percentage [0,100]
  ifelse(. >= 0 & . <= 1,
    . * 100,
    .
  ) %>%
  as.numeric()
```

This pipeline performs mutation analysis of SARS-CoV-2 and reports and 
quantifies the occurrence of lineages and single nucleotide (single-NT)
mutations.

The visualizations below provide an overview of the evolution of VOCs found
in the analyzed samples across given time points and locations. The abundance
values for the variants are derived by deconvolution. For details please consult
the [documentation](http://bioinformatics.mdc-berlin.de/pigx_docs/pigx-sars-cov-2.html#output-description)

This pipeline is part of
[PiGx](https://bioinformatics.mdc-berlin.de/pigx), a collection of
highly reproducible genomics pipelines
[developed](https://github.com/BIMSBbioinfo/pigx_sars-cov-2) by the
[Bioinformatics & Omics Data Science
platform](https://bioinformatics.mdc-berlin.de/) at the Berlin
Institute of Medical System Biology (BIMSB).


# Lineage abundance

These plots provide an overview of the relative frequency dynamics of
identified lineages at specific wastewater sampling locations over time. 

```{r sample_quality_score}
quality_df <- fread(params$overviewQC)

good_samples_df <- quality_df %>%
  filter(perc_muts_covered >= mutation_coverage_threshold)

bad_samples_df <- quality_df %>%
  filter(perc_muts_covered <  mutation_coverage_threshold)

approved_mut_plot <- df_mut %>%
  filter(samplename %in% good_samples_df$samplename)

weights <- quality_df %>%
  dplyr::select(c(samplename, total_reads))
```

```{r filter_plot_frames_samplescore, warning=TRUE}
# only use good samples for processing and visualiztaion
approved_var_plot <- df_var %>%
  filter(samplename %in% good_samples_df$samplename) %>%
  unique()
approved_mut_plot <- df_mut %>%
  filter(samplename %in% good_samples_df$samplename)

# check if filtered dataframe has actual values and get vars for conditional
# execution
VARIANTS_FOUND <- nrow(approved_var_plot) > 0
MUTATIONS_FOUND <- nrow(approved_mut_plot) > 0

# only run regression related chunks if at least two dates are left over
RUN_MUTATION_REGRESSION <- if (MUTATIONS_FOUND) {
  length(unique(approved_mut_plot$dates)) > 1
} else {
  FALSE
}

# define here in case mutation regression was not executed, as that would lead
# to an error otherwise
APPROVED_MUTATIONS_FOUND <- RUN_MUTATION_REGRESSION
SIGN_MUTS_FOUND          <- RUN_MUTATION_REGRESSION
```

```{asis plotting_variants_text, echo=VARIANTS_FOUND}
## Lineage abundances stacked {.tabset .tabset-fade}

The summary plot shows the results pooled by day and across locations by
weighted average using the read number as weights. Please use the tabs
to access the not-pooled plots for each location.
```


```{asis no_variants_warning, echo=!VARIANTS_FOUND}
<div class="alert alert-warning">
**Warning**:

Not enough variants were found or passed the quality filters.  
The associated plots are skipped.
</div>    
```

```{r variants_pooled_plot_gen, eval=VARIANTS_FOUND}
approved_var_plot_location_pooled <- pool_by_weighted_mean(
  approved_var_plot,
  weights, "day_location"
)

melted <- reshape2::melt(approved_var_plot_location_pooled,
  id.vars = c("dates", "samplename")
) %>%
  mutate(variable = give_priority_in_order(variable, "[Oo]thers"))

p_variant_pooled <- subset(melted) %>%
  group_by(dates) %>%
  arrange(variable) %>%
  mutate(value = round(value, 4)) %>%
  plot_ly(
    type = "scatter",
    mode = "lines+markers",
    stackgroup = "one",
    showlegend = TRUE,
    name = ~variable,
    x = ~dates,
    y = ~value,
    color = ~variable,
    colors = viridis_pal(option = "D")(6)
  ) %>%
  layout(
    title = "Summary over time",
    showlegend = TRUE,
    yaxis = list(title = "Frequency"),
    xaxis = list(title = "Dates")
  )
```


```{r variants_by_location_plot_gen, eval=VARIANTS_FOUND}
# Get the current figure size in pixels:
get_w <- function() {
  with(
    knitr::opts_current$get(c("fig.width", "dpi", "fig.retina")),
    fig.width * dpi / fig.retina
  )
}

get_h <- function() {
  with(
    knitr::opts_current$get(c("fig.height", "dpi", "fig.retina")),
    fig.height * dpi / fig.retina
  )
}

# plot variant frequencies by location, no pooling
melted <- reshape2::melt(approved_var_plot,
  id.vars = c(
    "dates", "samplename", "location_name",
    "coordinates_lat", "coordinates_long"
)) %>%
  mutate(variable = give_priority_in_order(variable, "[Oo]thers"))

location_plot <- function(melted, location) {
  subset(melted, location_name == location) %>%
    group_by(dates) %>%
    arrange(variable) %>%
    mutate(value = round(value, 4)) %>%
    plot_ly(
      type = "scatter",
      mode = "lines+markers",
      stackgroup = "one",
      showlegend = TRUE,
      name = ~variable,
      x = ~dates,
      y = ~value,
      color = ~variable,
      colors = viridis_pal(option = "D")(6)
    ) %>%
    layout(
      title = location,
      showlegend = TRUE,
      yaxis = list(title = "Frequency")
    )
}

locations <- as.character(unique(melted$location_name))

plot_list <- lapply(setNames(
  locations,
  locations
),
location_plot,
melted = melted
)
```

```{r variants_pooled_and_by_location_print, warning=TRUE,results='asis', fig.width=4, fig.height=4, eval=VARIANTS_FOUND}
if (length(plot_list) >= 1) {
  cat("###", "Summary over all locations", "{-}", "\n\n")
  suppressWarnings(print(htmltools::tagList(ggplotly(p_variant_pooled))))
  cat("\n\n")

  for (i in 1:length(locations)) {
    cat("###", locations[i], "{-}", "\n\n")
    suppressWarnings(print(htmltools::tagList(ggplotly(plot_list[[i]]))))
    cat("\n\n")
  }
} else {
  warning("Not enough data available to summarize and produce plots.")
}
```

```{asis, maps_for_variants_title, echo=VARIANTS_FOUND}
## Lineage abundances geo-localized

This plot visualizes proportions of identified lineage abundances at the
provided sampling locations.
```

```{r maps_for_variants_text, results='asis', eval=VARIANTS_FOUND}
cat(create_html_note(
  paste(
    "Locations of wastewater processing plants have been generated",
    "arbitrarily and do not correspond to actual locations."
  )
))

# TODO: Check formatting here
cat(
  "Click on a lineage in the legend to toggle its visibility in the map;\n",
  "double-click to view only the selected lineage.",
  ifelse(length(unique(approved_var_plot$dates)) > 1,
    yes = paste(
      "Use the slider to select a specific date or hit the",
      "*Play* button to display all snapshots successively. "
    ), no = ""
  )
)
```

```{r variant_location_maps_plot, out.width="900px", out.height="900px", eval=VARIANTS_FOUND}
# TODO: the note about arbitray locations should be enable to be turned on and
# off

approved_var_plot_day_pooled <- pool_by_weighted_mean(
  approved_var_plot,
  weights, "day"
)

melted <- reshape2::melt(
  approved_var_plot_day_pooled,
  id.vars = c(
    "dates",
    "samplename",
    "location_name",
    "coordinates_lat",
    "coordinates_long"
  ),
  rm.NA = TRUE
) %>%
  mutate(variable = give_priority_in_order(variable, "[Oo]thers")) %>%
  mutate(value = round(value, 4))

locations <- approved_var_plot_day_pooled %>%
  mutate(dates = as.character(strptime(dates, format = "%Y-%m-%d"))) %>%
  reshape2::melt(id.vars = c("coordinates_lat", "coordinates_long"))

p <- plot_ly(
  type = "scattermapbox",
  mode = "markers",
  colors = viridis_pal(option = "D")(6),
  width = 900,
  height = 500
) %>%
  add_trace(
    data = locations,
    size = 1,
    lon = ~coordinates_long,
    lat = ~coordinates_lat,
    opacity = 0.1,
    showlegend = FALSE,
    hoverinfo = "none",
    marker = list(
      sizemode = "diameter",
      color = "rgb(150, 150, 150)",
      opacity = 0
    )
  ) %>%
  add_trace(
    data = melted,
    lat = ~coordinates_lat,
    lon = ~coordinates_long,
    legendgroup = ~variable,
    showlegend = TRUE,
    frame = ~ as.character(strptime(dates, format = "%Y-%m-%d")),
    size = ~value,
    color = ~variable,
    hoverinfo = "text+name",
    hovertext = ~ paste0("Frequency: ", value),
    marker = list(sizemode = "diameter")
  ) %>%
  layout(
    mapbox = list(
      zoom = 5.5,
      center = list(
        lat = ~ median(coordinates_lat, na.rm = TRUE),
        lon = ~ median(coordinates_long,
          na.rm =
            TRUE
        )
      ),
      style = "open-street-map"
    )
  )

if (length(unique(approved_var_plot$dates)) > 1) {
  p %>% animation_slider(currentvalue = list(prefix = "Date: "))
} else {
  p
}
```

# Mutation dynamics

The following plots provide an overview of detected single nucleotide
mutations in different locations and how their relative frequency
changes over time. Furthermore, mutations showing a significant frequency
increase over time are highlighted.  

```{r mutation_notation, results='asis', eval=MUTATIONS_FOUND}
cat(create_html_note(str_glue(
  "Mutations are noted in the pattern of:",
  "\n _**gene {mut_str_sep} protein-sequence mutation ",
  "{mut_str_sep}{mut_str_sep} NT-sequence",
  "mutation**_\nPlease note that this translation was done for single",
  "mutations. Combinations of single-NT mutations that taken together may lead",
  "to a different amino acid are not yet taken into account."
)))
```


```{asis lm_table_title, echo=MUTATIONS_FOUND}
## Increasing mutations

To show the dynamic of significantly changing mutations over time a linear
regression model was applied to the mutation results across all samples.
```

```{asis lm_table_warning, echo=MUTATIONS_FOUND && !RUN_MUTATION_REGRESSION}
<div class="alert alert-warning">
**Warning**:

No mutations or not enough mutations were found to perform a
regression analysis.  
The associated plots are skipped.
</div>
```

```{r linear_regression_tables, warning=TRUE, results='asis', eval=RUN_MUTATION_REGRESSION}
sigmuts_df <- fread(params$mutation_sheet) %>%
  mutate(across(everything(), ~dplyr::na_if(.x, ""))) %>%
  # extract only the nucleotide mutation bit
  mutate(across(everything(),
    ~ str_extract(
      .x, str_glue("(?<={mut_str_sep})[[:alnum:]]+")
    )))

mutations_sig <- mutations_sig <- mutations_sig_unfiltered %>%
  filter(pvalues >= 0.05) %>%
  arrange(desc(coefficients))


SIGN_MUTS_FOUND <- nrow(mutations_sig) > 0
```

```{asis mut_reg_tables_caption, echo=SIGN_MUTS_FOUND}
The following table shows the mutations showing the strongest increasing trend
(p <= 0.05).

**Mutations with significant increase in frequency over time**
```

```{asis mut_reg_tables_warning, echo=!SIGN_MUTS_FOUND}
<div class="alert alert-warning">
**Warning**:

No Mutation with significant increase in frequency over time found.  
The associated plots are skipped.
</div>
```

```{r display_mut_reg_tables, results="asis", eval=SIGN_MUTS_FOUND}
# flag if mutation is signature mutation
mutations_sig <- mutations_sig %>%
  mutate(mut_str = str_extract(
    mutation,
    str_glue("(?<={mut_str_sep}{mut_str_sep})[[:alnum:]]+")
  )) %>%
  mutate(
    sigflag = ifelse(
      mut_str %in% unlist(sigmuts_df),
      "SigMut",
      "NoSigMut"
    )
  ) %>%
  dplyr::select(-mut_str)

print(htmltools::tagList(create_dt(mutations_sig)))

mutations_sig_download <- mutations_sig %>%
  dump_csv() %>%
  base64url::base64_urlencode()

cat(
  create_html_download_link(
    mutations_sig_download,
    "significant_mutations.csv"
  ),
  "\n\n"
)
```

```{r create_unfilt_mut_download, results="asis", eval=RUN_MUTATION_REGRESSION}
if (nrow(mutations_sig_unfiltered) > 0) {
  mutations_sig_unfiltered <- mutations_sig_unfiltered %>%
    mutate(mut_str = str_extract(
      mutation,
      str_glue("(?<={mut_str_sep}{mut_str_sep})[[:alnum:]]+"))) %>%
    mutate(
      sigflag = ifelse(
        mut_str %in%  unlist(sigmuts_df),
        "SigMut",
        "NoSigMut"
    )) %>%
    dplyr::select(-mut_str)

  mutations_sig_unfiltered_download <- mutations_sig_unfiltered %>%
    dump_csv() %>%
    base64url::base64_urlencode()

  cat(
    create_html_download_link(
      mutations_sig_unfiltered_download,
      "lm_res_all_mutations.csv"
    ),
    "\n\n"
  )
}
```

```{r filter_pool_mutations, eval=RUN_MUTATION_REGRESSION}
# filter good samples for only mutations with sig pvalues for plotting
filtered_approved_mut_plot <- dplyr::select(
  approved_mut_plot,
  c(
    samplename,
    dates,
    location_name,
    coordinates_lat,
    coordinates_long,
    mutations_sig$mutation
  )
)

# check if the filtered df has actual values besides meta data
APPROVED_MUTATIONS_FOUND <- (length(filtered_approved_mut_plot) > 5) &&
  (nrow(filtered_approved_mut_plot) > 0)

approved_mut_plot_location_pooled <- pool_by_mean(filtered_approved_mut_plot,
  na_handling = TRUE,
  group_fun = "day_location"
)
```

```{asis mutation_trends_pooled_text, echo=APPROVED_MUTATIONS_FOUND}
## Trending mutations over time {.tabset .tabset-fade}

These plots show the relative frequency of detected mutations with strong
increasing trends in samples at specific wastewater sampling locations and
how the frequencies change over time. Please use the tabs to access the
not-pooled plots for each location.
```

```{r mutation_trends_pooled_plot_gen, eval=APPROVED_MUTATIONS_FOUND}
melted <- reshape2::melt(approved_mut_plot_location_pooled,
  id.vars = c("dates", "samplename")
)

melted <- melted %>%
  mutate(mut_str = str_extract(
    variable,
    str_glue("(?<={mut_str_sep}{mut_str_sep})[[:alnum:]]+"))) %>%
  mutate(
    sigflag = ifelse(
      mut_str %in%  unlist(sigmuts_df),
      "SigMut",
      "NoSigMut"
  )) %>%
  dplyr::select(-mut_str)

# sort by dates
idx <- order(melted$dates)
melted <- melted[idx, ]

p_mutations_pooled <- subset(melted) %>%
  group_by(dates) %>%
  arrange(variable) %>%
  ungroup() %>%
  plot_ly(
    type = "scatter",
    mode = "lines+markers",
    symbol = ~sigflag,
    symbols = c("circle", "square"),
    x = ~dates,
    y = ~value,
    name = ~variable,
    connectgaps = TRUE,
    color = ~variable,
    colors = viridis_pal(option = "H")(20)
  ) %>%
  layout(
    title = summary,
    yaxis = list(title = "Frequency")
  )
```


```{r mutation_trends_by_location_plot_gen, eval=APPROVED_MUTATIONS_FOUND}
plot_muts <- function(melted, location) {
  subset(melted, location_name == location) %>%
    group_by(dates) %>%
    arrange(variable) %>%
    ungroup() %>%
    plot_ly(
      type = "scatter",
      mode = "lines+markers",
      symbol = ~sigflag,
      symbols = c("circle", "hourglass"),
      x = ~dates,
      y = ~value,
      name = ~variable,
      color = ~variable,
      colors = viridis_pal(option = "H")(20),
      connectgaps = TRUE
    ) %>%
    layout(
      title = location,
      yaxis = list(title = "Frequency")
    )
}

melted <- reshape2::melt(filtered_approved_mut_plot,
  id.vars = c(
    "dates", "samplename", "location_name",
    "coordinates_lat", "coordinates_long"
  )
) %>%
  mutate(mut_str = str_extract(
    variable,
    str_glue("(?<={mut_str_sep}{mut_str_sep})[[:alnum:]]+"))) %>%
  mutate(
    sigflag = ifelse(
      mut_str %in%  unlist(sigmuts_df),
      "SigMut",
      "NoSigMut"
  )) %>%
  dplyr::select(-mut_str)

# sort by dates
idx <- order(melted$dates)
melted <- melted[idx, ]

locations <- as.character(unique(melted$location_name))

plot_list <- lapply(setNames(
  locations,
  locations
),
plot_muts,
melted = melted
)
```


```{r mutation_trends_by_location_plot_print, results='asis', fig.width=4, fig.height=4, eval=APPROVED_MUTATIONS_FOUND}
cat("###", "Summary over all locations", "{-}", "\n\n")
print(htmltools::tagList(ggplotly(p_mutations_pooled)))
cat("\n\n")

for (i in 1:length(locations)) {
  cat("###", locations[i], "{-}", "\n\n")
  print(htmltools::tagList(ggplotly(plot_list[[i]])))
  cat("\n\n")
}
```

```{asis muts_by_loc_and_date_title, echo=APPROVED_MUTATIONS_FOUND}
## Trending mutations geo-localized

This plot visualizes proportions of identified single mutation dynamics at the
provided sampling locations.
```

```{r muts_by_loc_and_date_text, results='asis', eval=APPROVED_MUTATIONS_FOUND}
cat(
  create_html_note(
    paste0(
      "Locations of wastewater processing plants have been\n",
      "generated arbitrarily and do not correspond to actual ",
      "locations."
    )
  )
)

cat(
  "Click on a lineage in the legend to toggle its visibility in the map;\n",
  "double-click to view only the selected lineage.",
  ifelse(
    length(unique(approved_mut_plot$dates)) > 1,
    yes = paste(
      "Use the slider to select a specific date or hit the *Play*",
      "button to display all snapshots successively. "
    ),
    no = ""
  )
)
```


```{r muts_by_loc_and_date_plot, out.width="900px", out.height="900px", eval=APPROVED_MUTATIONS_FOUND}
# TODO: find a way to only show dynamic of one single mutation over the whole
# time

approved_mut_plot_day_pooled <- pool_by_mean(
  filtered_approved_mut_plot,
  TRUE, "day"
)

melted <- reshape2::melt(approved_mut_plot_day_pooled,
  id.vars = c(
    "dates", "samplename", "location_name",
    "coordinates_lat", "coordinates_long"
  ),
  rm.NA = TRUE
)
# check if there are actual values except the meta data
melted <- melted %>% mutate(value = round(value, 4))

locations <- approved_mut_plot_day_pooled %>%
  mutate(dates = as.character(strptime(dates, format = "%Y-%m-%d"))) %>%
  reshape2::melt(id.vars = c("coordinates_lat", "coordinates_long"))

p <- plot_ly(
  type = "scattermapbox",
  colors = viridis_pal(option = "H")(20),
  mode = "markers",
  width = 900,
  height = 500
) %>%
  add_trace(
    size = 1,
    data = locations,
    lon = ~coordinates_long,
    lat = ~coordinates_lat,
    opacity = 0.1,
    showlegend = FALSE,
    hoverinfo = "none",
    marker = list(
      sizemode = "diameter",
      color = "rgb(150, 150, 150)",
      opacity = 0
    )
  ) %>%
  add_trace(
    data = melted,
    lat = ~coordinates_lat,
    lon = ~coordinates_long,
    legendgroup = ~variable,
    showlegend = TRUE,
    frame = ~ as.character(strptime(dates, format = "%Y-%m-%d")),
    size = ~value,
    color = ~variable,
    hoverinfo = "text+name",
    hovertext = ~ paste0("Frequency: ", value),
    marker = list(sizemode = "diameter")
  ) %>%
  layout(
    title = ~dates,
    autosize = TRUE,
    mapbox = list(
      zoom = 5.5,
      center = list(
        lat = ~ median(coordinates_lat, na.rm = TRUE),
        lon = ~ median(coordinates_long, na.rm = TRUE)
      ),
      style = "open-street-map"
    )
  )

if (length(unique(approved_mut_plot_day_pooled$dates)) > 1) {
  p %>% animation_slider(currentvalue = list(prefix = "Date: "))
} else {
  p
}
```

# Data summaries and download


```{r table_var_frqs}
df_var_download <- df_var %>%
  dump_csv() %>%
  base64url::base64_urlencode()
```

Frequencies per lineage per sample, derived by deconvolution, pooled by weighted
mean by read number: 

`r create_html_download_link(df_var_download,filename = "variant_frequencies.csv")`

```{r table_mut_freqs}
df_mut_download <- df_mut %>%
  dump_csv() %>%
  base64url::base64_urlencode()
```

Frequencies per mutation per sample

`r create_html_download_link(df_mut_download, filename = "mutation_frequencies.csv")`

```{r mutation_counts}
count_frame <- fread(params$mut_count_file)

# show and make downloadable
count_frame_download <- count_frame %>%
  dump_csv() %>%
  base64url::base64_urlencode()
```

Counts of mutations found across all sample and per sample

`r create_html_download_link(count_frame_download, "mutation_counts.csv")`


# Detailed per-sample reports

For every sample three reports are generated:  
    
  * a QC report reporting general statistics and amplicon coverage  
  * a lineage report including tables summarizing the mutation
    calling and the deconvolution results for the abundance of VOCs  
  * a taxonomic classification report including a pie chart showing the
    analysis of the unaligned reads.

The reports for each sample can be accessed here:

```{r generate overview}
sample_sheet <- fread(params$sample_sheet)
sample_names <- sample_sheet$name
reports <- list(
  list(
    "suffix" = ".variantreport_per_sample.html",
    "name" = "variant report"
  ),
  list(
    "suffix" = ".qc_report_per_sample.html",
    "name" = "QC report"
  ),
  list(
    "suffix" = ".taxonomic_classification.html",
    "name" = "taxonomic classification"
  )
)

df <- as.data.frame(dplyr::select(sample_sheet, name, location_name, date))

links <- lapply(sample_names, function(sample) {
  as.vector(lapply(reports, function(report) {
    paste0("<a href=", sample, report$suffix, ">", report$name, "</a>")
  }))
})

df$reports <- links
datatable(df, options = list(
  fixedColumns = TRUE,
  scrollY = 180,
  scrollX = TRUE,
  scroller = TRUE,
  dom = "Slfrtip"
))
```

# Discarded samples 

Prior visualization and regression analysis each sample gets a quality score
depending on proportion of covered reference genome and proportion of covered
signature mutation locations. Results from samples without sufficient coverage
measures (< `r mutation_coverage_threshold`%) are not included in the
visualizations or the linear regression calculations. 

Table 1: Quality description of samples not meeting the requirement of
covering at least `r mutation_coverage_threshold`% of signature mutations.

```{r table_sample_quality_score}
bad_samp_rename_vec <- c(
  "Sample name" = "samplename",
  "Collection date" = "date",
  "n reads" = "total_reads",
  "Trimmed reads in R1" = "read_num_trimmed_r1",
  "Trimmed reads in R2" = "read_num_trimmed_r2",
  "Unaligned reads" = "unaligned_reads_from_file",
  "Aligned reads" = "numreads",
  "Bases covered by reads" = "covbases",
  "% of ref. genome covered" = "coverage",
  "Mean depth" = "meandepth",
  "Mean base qual." = "meanbaseq",
  "Mean map qual." = "meanmapq",
  "Total mutations" = "n_loc_total",
  "Covered mutations" = "n_loc_covered",
  "Uncovered mutations" = "n_loc_no_cov",
  "Mean read depth at muts." = "avg_loc_cvrg",
  "% of tot. muts. covered" = "perc_muts_covered",
  "Reads removed during preprocessing" = "reads_removed_by_QC"
)

bad_samples_df %>%
  select(-all_of(setdiff(names(.), bad_samp_rename_vec))) %>%
    mutate(
      date = format(date, "%d.%m.%Y, %H:%M"),
      coverage = paste0(round(coverage, 1), "%"),
      perc_muts_covered  = paste0(round(perc_muts_covered, 1), "%"),
      meandepth = round(meandepth, 1),
      avg_loc_cvrg = round(avg_loc_cvrg, 1)
    ) %>%
  rename(!!!bad_samp_rename_vec) %>%
  create_dt()
```
