---
title: "SARS-CoV-2 Wastewater Sampling Reports"
nav: "Overview"
author: "BIMSB Bioinformatics Platform"
date: '`r format(as.POSIXct(if ("" != Sys.getenv("SOURCE_DATE_EPOCH")) { as.numeric(Sys.getenv("SOURCE_DATE_EPOCH")) } else { Sys.time() }, origin="1970-01-01"), "%Y-%m-%d %H:%M:%S")`'
params:
  variants_csv: ""
  mutations_csv: ""
  sample_sheet: ""
  mutation_sheet: ""
  mutation_coverage_threshold: ""
  logo: ""
  fun_tbls: ""
  coverage_dir: ""
  output_dir: ""
  overviewQC: ""
  fun_lm: ""
  fun_cvrg_scr: ""
  fun_pool: ""
  fun_index: ""
  unfiltered_mutation_sig_file: ""
  mut_count_file: ""
---

<style>
.pigx_info {
  background-image: url(params$logo);
}

.notice {
  margin-left: -12px;
  padding-left: 6px;
  border-left: 6px solid #ff9999;
}
.dropdown-menu {
  max-height: 200px;
  overflow-y: scroll;}

</style>

<div id="logo" align="top">
`r knitr::include_graphics(params$logo)`
</div>

```{r knitr_chunk_options, message=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r alerts}
# you may trigger these formatted notifications by enabling the corresponding
# settings in the respective chunk:
# error --> error=TRUE
# warning --> warning=TRUE
# message --> message=TRUE

# format error, warning and messages with html styles
# https://selbydavid.com/vignettes/alerts.html
knitr::knit_hooks$set(
  error = function(x, options) {
    paste('\n\n<div class="alert alert-danger">',
      gsub("^##", "\n", gsub("^##\ Error", "**Error**", x)),
      "</div>",
      sep = "\n"
    )
  },
  warning = function(x, options) {
    paste('\n\n<div class="alert alert-warning">',
      gsub("##", "\n", gsub("^##\ Warning:", "**Warning**", x)),
      "</div>",
      sep = "\n"
    )
  },
  message = function(x, options) {
    paste('\n\n<div class="alert alert-info">',
      gsub("##", "\n", x),
      "</div>",
      sep = "\n"
    )
  }
)
```

```{r libraries}
library(plotly)
library(htmltools)
library(reshape2)
library(base64url)
library(DT)
library(data.table)
library(stringr)
library(ggplot2)
library(dplyr)
library(viridis)
```

```{r load_data}
# TODO given as input? or only the scripts dir? similar variant_report
source(params$fun_cvrg_scr)
source(params$fun_pool)
source(params$fun_index)
source(params$fun_lm)

mutations_sig_unfiltered <- fread(params$unfiltered_mutation_sig_file)

df_var <- fread(params$variants_csv,
  header = TRUE,
  check.names = FALSE
)
df_mut <- fread(params$mutations_csv,
  header = TRUE,
  check.names = FALSE
)

var_sep <- ":"
aa_sep  <- "/"
```

```{r format_threshold}
mutation_coverage_threshold <- params$mutation_coverage_threshold %>%
  # check if value is given as fraction [0,1] or percentage [0,100]
  ifelse(. >= 0 & . <= 1,
    . * 100,
    .
  ) %>%
  as.numeric()
```

This pipeline performs mutation analysis of SARS-CoV-2 and reports and 
quantifies the occurrence of lineages and single nucleotide (single-NT)
mutations.

The visualizations below provide an overview of the evolution of VOCs found
in the analyzed samples across given time points and locations. The abundance 
values for the variants are derived by deconvolution. For details please 
consult the 
[documentation](http://bioinformatics.mdc-berlin.de/pigx_docs/pigx-sars-cov-2.html#output-description))

This pipeline is part of
[PiGx](https://bioinformatics.mdc-berlin.de/pigx), a collection of
highly reproducible genomics pipelines
[developed](https://github.com/BIMSBbioinfo/pigx_sars-cov-2) by the
[Bioinformatics & Omics Data Science
platform](https://bioinformatics.mdc-berlin.de/) at the Berlin
Institute of Medical System Biology (BIMSB).


# Lineage abundance

These plots provide an overview of the relative frequency dynamics of
identified lineages at specific wastewater sampling locations over time. 

```{r sample_quality_score}
coverages_df <- merge(get_genome_cov(params$coverage_dir),
  get_mutation_cov(params$coverage_dir),
  by = "samplename"
) %>%
  mutate(
    proport_muts_covered = round(
      (as.numeric(total_muts_cvrd) * 100) / as.numeric(total_num_muts), 1
    )
  )

if (!(length(coverages_df) == 0)) {
  # take only the samples over the mutation coverage threshold
  good_samples_df <- coverages_df %>%
    filter(as.numeric(proport_muts_covered) >= mutation_coverage_threshold)

  bad_samples_df <- coverages_df %>%
    filter(!(samplename %in% good_samples_df$samplename))
} else {
  warning("\n No coverage values found.")
}
```

```{r filter_plot_frames_samplescore, warning=TRUE}
# only use good samples for processing and visualiztaion
approved_var_plot <- df_var %>%
  filter(samplename %in% good_samples_df$samplename) %>%
  unique()
approved_mut_plot <- df_mut %>%
  filter(samplename %in% good_samples_df$samplename)

# pool the samples per day, discard locations
weights <- read.csv(params$overviewQC, header = TRUE, check.names = FALSE) %>%
  dplyr::select(c(samplename, total_reads))

# check if filtered dataframe has actual values and get vars for conditional
# execution
VARIANTS_FOUND <- nrow(approved_var_plot) > 0
MUTATIONS_FOUND <- nrow(approved_mut_plot) > 0

# only run regression related chunks if at least two dates are left over
RUN_MUTATION_REGRESSION <- if (MUTATIONS_FOUND) {
  length(unique(approved_mut_plot$dates)) > 1
} else {
  FALSE
}

# define here in case mutation regression was not executed, as that would lead
# to an error otherwise
APPROVED_MUTATIONS_FOUND <- RUN_MUTATION_REGRESSION


if (! VARIANTS_FOUND) {
  warning(paste0(
    "\nNot enough variants were found or passed the quality filters.",
    "\nThe associated plots are skipped."
  ))
}
```

```{r plotting_variants_text, results='asis', fig.width=4, fig.height=4, eval=VARIANTS_FOUND}
cat("## Lineage abundances stacked {.tabset .tabset-fade}\n\n",
  "The summary plot shows the results pooled by day and across locations by ",
  "weighted average using the read number as weights. Please use the tabs ",
  "to access the not-pooled plots for each location.",
  sep = ""
)
```

```{r variants_pooled_plot_gen, eval=VARIANTS_FOUND}
approved_var_plot_location_pooled <- pool_by_weighted_mean(
  approved_var_plot,
  weights, "day_location"
)

melted <- reshape2::melt(approved_var_plot_location_pooled,
  id.vars = c("dates", "samplename")
)

p_variant_pooled <- subset(melted) %>%
  group_by(dates) %>%
  mutate(variable = give_priority_in_order(variable, "[Oo]thers")) %>%
  mutate(value = round(value, 4)) %>%
  plot_ly(
    type = "scatter",
    mode = "lines+markers",
    stackgroup = "one",
    showlegend = TRUE,
    name = ~variable,
    x = ~dates,
    y = ~value,
    color = ~variable,
    colors = viridis_pal(option = "D")(6)
  ) %>%
  layout(
    title = "Summary over time",
    showlegend = TRUE,
    yaxis = list(title = "Frequency"),
    xaxis = list(title = "Dates")
  )
```


```{r variants_by_location_plot_gen, eval=VARIANTS_FOUND}
# Get the current figure size in pixels:
get_w <- function() {
  with(
    knitr::opts_current$get(c("fig.width", "dpi", "fig.retina")),
    fig.width * dpi / fig.retina
  )
}

get_h <- function() {
  with(
    knitr::opts_current$get(c("fig.height", "dpi", "fig.retina")),
    fig.height * dpi / fig.retina
  )
}

# plot variant frequencies by location, no pooling
melted <- reshape2::melt(approved_var_plot,
  id.vars = c(
    "dates", "samplename", "location_name",
    "coordinates_lat", "coordinates_long"
  )) %>%
  mutate(
    variable = give_priority_in_order(variable, "[Oo]thers"),

    # conversion to character necessary, if it remains a date the plot will
    # separate the dots on every date
    dates = as.character(dates)
  )

location_plot <- function(melted, location) {
  subset(melted, location_name == location) %>%
    group_by(dates) %>%
    arrange(variable) %>%
    mutate(value = round(value, 4)) %>%
    plot_ly(
      type = "scatter",
      mode = "lines+markers",
      stackgroup = "one",
      showlegend = TRUE,
      name = ~variable,
      x = ~dates,
      y = ~value,
      color = ~variable,
      colors = viridis_pal(option = "D")(6)
    ) %>%
    layout(
      title = location,
      showlegend = TRUE,
      yaxis = list(title = "Frequency")
    )
}

locations <- as.character(unique(melted$location_name))

plot_list <- lapply(setNames(
  locations,
  locations
),
location_plot,
melted = melted
)
```

```{r variants_pooled_and_by_location_print, warning=TRUE,results='asis', fig.width=4, fig.height=4, eval=VARIANTS_FOUND}
if (length(plot_list) >= 1) {
  cat("###", "Summary over all locations", "{-}", "\n\n")
  suppressWarnings(print(htmltools::tagList(ggplotly(p_variant_pooled))))
  cat("\n\n")

  for (i in 1:length(locations)) {
    cat("###", locations[i], "{-}", "\n\n")
    suppressWarnings(print(htmltools::tagList(ggplotly(plot_list[[i]]))))
    cat("\n\n")
  }
} else {
  warning("Not enough data available to summarize and produce plots.")
}
```


```{r maps_for_variants_text, results='asis', eval=VARIANTS_FOUND}
cat("## Lineage abundances geo-localized\n\n",
  "This plot visualizes proportions of identified lineage ",
  "abundances at the provided sampling locations.",
  sep = ""
)

cat(create_html_note(
  paste(
    "Locations of wastewater processing plants have been generated",
    "arbitrarily and do not correspond to actual locations."
  )
))

# TODO: Check formatting here
cat(
  "Click on a lineage in the legend to toggle its visibility in the map;\n",
  "double-click to view only the selected lineage.",
  ifelse(length(unique(approved_var_plot$dates)) > 1,
    yes = paste(
      "Use the slider to select a specific date or hit the",
      "*Play* button to display all snapshots successively. "
    ), no = ""
  )
)
```

```{r variant_location_maps_plot, out.width="900px", out.height="900px", eval=VARIANTS_FOUND}
# TODO: the note about arbitray locations should be enable to be turned on and
# off

approved_var_plot_day_pooled <- pool_by_weighted_mean(
  approved_var_plot,
  weights, "day"
)

melted <- reshape2::melt(
  approved_var_plot_day_pooled,
  id.vars = c(
    "dates",
    "samplename",
    "location_name",
    "coordinates_lat",
    "coordinates_long"
  ),
  rm.NA = TRUE
) %>%
  mutate(variable = give_priority_in_order(variable, "[Oo]thers")) %>%
  mutate(value = round(value, 4))

locations <- approved_var_plot_day_pooled %>%
  mutate(dates = as.character(strptime(dates, format = "%Y-%m-%d"))) %>%
  reshape2::melt(id.vars = c("coordinates_lat", "coordinates_long"))

p <- plot_ly(
  type = "scattermapbox",
  mode = "markers",
  colors = viridis_pal(option = "D")(6),
  width = 900,
  height = 500
) %>%
  add_trace(
    data = locations,
    size = 1,
    lon = ~coordinates_long,
    lat = ~coordinates_lat,
    opacity = 0.1,
    showlegend = FALSE,
    hoverinfo = "none",
    marker = list(
      sizemode = "diameter",
      color = "rgb(150, 150, 150)",
      opacity = 0
    )
  ) %>%
  add_trace(
    data = melted,
    lat = ~coordinates_lat,
    lon = ~coordinates_long,
    legendgroup = ~variable,
    showlegend = TRUE,
    frame = ~ as.character(strptime(dates, format = "%Y-%m-%d")),
    size = ~value,
    color = ~variable,
    hoverinfo = "text+name",
    hovertext = ~ paste0("Frequency: ", value),
    marker = list(sizemode = "diameter")
  ) %>%
  layout(
    mapbox = list(
      zoom = 5.5,
      center = list(
        lat = ~ median(coordinates_lat, na.rm = TRUE),
        lon = ~ median(coordinates_long,
          na.rm =
            TRUE
        )
      ),
      style = "open-street-map"
    )
  )

if (length(unique(approved_var_plot$dates)) > 1) {
  p %>% animation_slider(currentvalue = list(prefix = "Date: "))
} else {
  p
}
```

# Mutation dynamics

The following plots provide an overview of detected single nucleotide
mutations in different locations and how their relative frequency
changes over time. Furthermore, mutations showing a significant frequency 
increase over time are highlighted.  

```{r mutation_notation, results='asis', eval=MUTATIONS_FOUND}
cat(create_html_note(str_glue(
  "Mutations are noted in the pattern of:",
  "\n _**gene {aa_sep} protein-sequence mutation {aa_sep}{aa_sep} NT-sequence",
  "mutation**_\nPlease note that this translation was done for single",
  "mutations. Combinations of single-NT mutations that taken together may lead",
  "to a different amino acid are not yet taken into account."
)))
```


```{r title_lm_table, results = 'asis', warning=TRUE, eval=MUTATIONS_FOUND}
cat(
  "## Increasing mutations\n\n",
  "To show the dynamic of significantly changing mutations over time a linear ",
  "regression model was applied to the mutation results across all samples.",
  sep = ""
)

if (!RUN_MUTATION_REGRESSION) {
  warning(paste(
    "No mutations or not enough mutations were found to perform a",
    "regression analysis.\nThe associated plots are skipped.\n"
  ))
}
```


```{r linear_regression_tables, warning=TRUE, results='asis', eval=RUN_MUTATION_REGRESSION}
mutations_sig <- filter_lm_res_top20(mutations_sig_unfiltered, 0.05)

sigmuts_df <- fread(params$mutation_sheet) %>%
  na_if("") %>%
  # remove gene name of for easier matching
  mutate(across(everything(),
                ~ str_extract(
                  .x, str_glue("(?<={var_sep})[[:alnum:]]+")
                )))

if (nrow(mutations_sig) > 0) {
  # flag if mutation is signature mutation
  mutations_sig <- mutations_sig %>%
    mutate(mut_str = str_extract(
          mutation,
          str_glue("(?<={aa_sep}{aa_sep})[[:alnum:]]+"))) %>%
    mutate(
      sigflag = ifelse(
         mut_str %in%  unlist(sigmuts_df),
          "SigMut",
          ""
        )) %>%
    dplyr::select(- mut_str)

  cat(
    "The following table shows the mutations showing ",
    "the strongest increasing trend (p <= 0.05).",
    "The number of trending mutation is restricted to the top 20.",
    "\n\n**Mutations with significant increase in frequency over time**\n"
  )

  print(htmltools::tagList(create_dt(mutations_sig)))

  mutations_sig_download <- mutations_sig %>%
    dump_csv() %>%
    base64url::base64_urlencode()
  cat(
    create_html_download_link(
      mutations_sig_download,
      "significant_mutations.csv"
    ),
    "\n\n"
  )
} else {
  warning(
    "No Mutation with significant increase in frequency over time found.",
    "\nThe associated plots are skipped.\n"
  )
}

if (nrow(mutations_sig_unfiltered) > 0) {
  mutations_sig_unfiltered <- mutations_sig_unfiltered %>%
    mutate(mut_str = str_extract(
          mutation,
          str_glue("(?<={aa_sep}{aa_sep})[[:alnum:]]+"))) %>%
    mutate(
      sigflag = ifelse(
         mut_str %in%  unlist(sigmuts_df),
          "SigMut",
          ""
        )) %>%
    dplyr::select(- mut_str)

  mutations_sig_unfiltered_download <- mutations_sig_unfiltered %>%
    dump_csv() %>%
    base64url::base64_urlencode()

  cat(
    create_html_download_link(
      mutations_sig_unfiltered_download,
      "lm_res_all_mutations.csv"
    ),
    "\n\n"
  )
}
```

```{r filter_pool_mutations, eval=RUN_MUTATION_REGRESSION}
# filter good samples for only mutations with sig pvalues for plotting
filtered_approved_mut_plot <- dplyr::select(
  approved_mut_plot,
  c(
    samplename,
    dates,
    location_name,
    coordinates_lat,
    coordinates_long,
    mutations_sig$mutation
  )
)

# check if the filtered df has actual values besides meta data
APPROVED_MUTATIONS_FOUND <- (length(filtered_approved_mut_plot) > 5) &&
  (nrow(filtered_approved_mut_plot) > 0)

approved_mut_plot_location_pooled <- pool_by_mean(filtered_approved_mut_plot,
  na_handling = TRUE,
  group_fun = "day_location"
)
```

```{r mutation_trends_pooled_text, results='asis', eval=APPROVED_MUTATIONS_FOUND}
cat(
  "## Trending mutations over time {.tabset .tabset-fade}\n\n",
  "These plots show the relative frequency of detected mutations with strong ",
  "increasing trends in samples at specific wastewater sampling locations and ",
  "how the frequencies change over time. Please use the tabs to access the ",
  "not-pooled plots for each location.",
  sep = ""
)
```


```{r mutation_trends_pooled_plot_gen, eval=APPROVED_MUTATIONS_FOUND}
melted <- reshape2::melt(approved_mut_plot_location_pooled,
  id.vars = c("dates", "samplename")
)

melted <- melted %>%
    mutate(mut_str = str_extract(
          variable,
          str_glue("(?<={aa_sep}{aa_sep})[[:alnum:]]+"))) %>%
    mutate(
      sigflag = ifelse(
         mut_str %in%  unlist(sigmuts_df),
          "SigMut",
          "NoSigMut"
        )) %>%
    dplyr::select(- mut_str) %>%

    # sort by dates
    arrange(dates) %>%

    # coerce dates to string, same reason as in the variants plot
    mutate(dates = as.character(dates))


p_mutations_pooled <- subset(melted) %>%
  group_by(dates) %>%
  arrange(variable) %>%
  ungroup() %>%
  plot_ly(
    type = "scatter",
    mode = "lines+markes",
    symbol = ~sigflag,
    symbols = c("circle", "square"),
    x = ~dates,
    y = ~value,
    name = ~variable,
    connectgaps = TRUE,
    color = ~variable,
    colors = viridis_pal(option = "H")(20)
  ) %>%
  layout(
    title = summary,
    yaxis = list(title = "Frequency")
  )
```


```{r mutation_trends_by_location_plot_gen, eval=APPROVED_MUTATIONS_FOUND}
plot_muts <- function(melted, location) {
  subset(melted, location_name == location) %>%
    group_by(dates) %>%
    arrange(variable) %>%
    ungroup() %>%
    plot_ly(
      type = "scatter",
      mode = "lines+markers",
      symbol = ~sigflag,
      symbols = c("circle", "hourglass"),
      x = ~dates,
      y = ~value,
      name = ~variable,
      color = ~variable,
      colors = viridis_pal(option = "H")(20),
      connectgaps = TRUE
    ) %>%
    layout(
      title = location,
      yaxis = list(title = "Frequency")
    )
}

# TODO Unify the sigflag values across the report
melted <- reshape2::melt(filtered_approved_mut_plot,
  id.vars = c(
    "dates", "samplename", "location_name",
    "coordinates_lat", "coordinates_long"
  )
)  %>%
    mutate(mut_str = str_extract(
          variable,
          str_glue("(?<={aa_sep}{aa_sep})[[:alnum:]]+"))) %>%
    mutate(
      sigflag = ifelse(
         mut_str %in%  unlist(sigmuts_df),
          "SigMut",
          NA
        )) %>%
    dplyr::select(- mut_str) %>%

    # sort by dates
    arrange(dates) %>%

    # coerce dates to string, same reason as in the variants plot
    mutate(dates = as.character(dates))

locations <- as.character(unique(melted$location_name))

plot_list <- lapply(setNames(
  locations,
  locations
),
plot_muts,
melted = melted
)
```


```{r mutation_trends_by_location_plot_print, results='asis', fig.width=4, fig.height=4, eval=APPROVED_MUTATIONS_FOUND}
cat("###", "Summary over all locations", "{-}", "\n\n")
print(htmltools::tagList(ggplotly(p_mutations_pooled)))
cat("\n\n")

for (i in 1:length(locations)) {
  cat("###", locations[i], "{-}", "\n\n")
  print(htmltools::tagList(ggplotly(plot_list[[i]])))
  cat("\n\n")
}
```



```{r muts_by_loc_and_date_text, results='asis', eval=APPROVED_MUTATIONS_FOUND}

cat("## Trending mutations geo-localized\n\nThis plot visualizes proportions ",
  "of identified single mutation dynamics at the provided sampling ",
  "locations.",
  sep = ""
)

cat(create_html_note(paste(
    "Locations of wastewater processing plants have been\n",
    "generated arbitrarily and do not correspond to actual ",
    "locations.",
    sep = ""
)))

cat(
  "Click on a lineage in the legend to toggle its visibility in the map;\n",
  "double-click to view only the selected lineage.",
  ifelse(
    length(unique(approved_mut_plot$dates)) > 1,
    yes = paste(
      "Use the slider to select a specific date or hit the *Play*",
      "button to display all snapshots successively. "
    ),
    no = ""
  )
)
```


```{r muts_by_loc_and_date_plot, out.width="900px", out.height="900px", eval=APPROVED_MUTATIONS_FOUND}
# TODO: find a way to only show dynamic of one single mutation over the whole
# time

approved_mut_plot_day_pooled <- pool_by_mean(
  filtered_approved_mut_plot,
  TRUE, "day"
)

melted <- reshape2::melt(approved_mut_plot_day_pooled,
  id.vars = c(
    "dates", "samplename", "location_name",
    "coordinates_lat", "coordinates_long"
  ),
  rm.NA = TRUE
)
# check if there are actual values except the meta data
melted <- melted %>% mutate(value = round(value, 4))

locations <- approved_mut_plot_day_pooled %>%
  mutate(dates = as.character(strptime(dates, format = "%Y-%m-%d"))) %>%
  reshape2::melt(id.vars = c("coordinates_lat", "coordinates_long"))

p <- plot_ly(
  type = "scattermapbox",
  colors = viridis_pal(option = "H")(20),
  mode = "markers",
  width = 900,
  height = 500
) %>%
  add_trace(
    size = 1,
    data = locations,
    lon = ~coordinates_long,
    lat = ~coordinates_lat,
    opacity = 0.1,
    showlegend = FALSE,
    hoverinfo = "none",
    marker = list(
      sizemode = "diameter",
      color = "rgb(150, 150, 150)",
      opacity = 0
    )
  ) %>%
  add_trace(
    data = melted,
    lat = ~coordinates_lat,
    lon = ~coordinates_long,
    legendgroup = ~variable,
    showlegend = TRUE,
    frame = ~ as.character(strptime(dates, format = "%Y-%m-%d")),
    size = ~value,
    color = ~variable,
    hoverinfo = "text+name",
    hovertext = ~ paste0("Frequency: ", value),
    marker = list(sizemode = "diameter")
  ) %>%
  layout(
    title = ~dates,
    autosize = TRUE,
    mapbox = list(
      zoom = 5.5,
      center = list(
        lat = ~ median(coordinates_lat, na.rm = TRUE),
        lon = ~ median(coordinates_long, na.rm = TRUE)
      ),
      style = "open-street-map"
    )
  )

if (length(unique(approved_mut_plot_day_pooled$dates)) > 1) {
  p %>% animation_slider(currentvalue = list(prefix = "Date: "))
} else {
  p
}
```

# Data summaries and download


```{r table_var_frqs}
df_var_download <- df_var %>%
  dump_csv() %>%
  base64url::base64_urlencode()
```

Frequencies per lineage per sample, derived by deconvolution, pooled by weighted
mean by read number: 

`r create_html_download_link(df_var_download,filename = "variant_frequencies.csv")`

```{r table_mut_freqs}
df_mut_download <- df_mut %>%
  dump_csv() %>%
  base64url::base64_urlencode()
```

Frequencies per mutation per sample

`r create_html_download_link(df_mut_download, filename = "mutation_frequencies.csv")`

```{r mutation_counts}
count_frame <- read.csv(params$mut_count_file)

# show and make downloadable
count_frame_download <- count_frame %>%
  dump_csv() %>%
  base64url::base64_urlencode()
```

Counts of mutations found across all sample and per sample

`r create_html_download_link(count_frame_download, "mutation_counts.csv")`


# Detailed per-sample reports

For every sample three reports are generated:  
    
  * a QC report reporting general statistics and amplicon coverage  
  * a lineage report including tables summarizing the mutation
    calling and the deconvolution results for the abundance of VOCs  
  * a taxonomic classification report including a pie chart showing the
    analysis of the unaligned reads.

The reports for each sample can be accessed here:

```{r generate overview}
sample_sheet <- fread(params$sample_sheet)
sample_names <- sample_sheet$name
reports <- list(
  list(
    "suffix" = ".variantreport_p_sample.html",
    "name" = "variant report"
  ),
  list(
    "suffix" = ".qc_report_per_sample.html",
    "name" = "QC report"
  ),
  list(
    "suffix" = ".taxonomic_classification.html",
    "name" = "taxonomic classification"
  )
)

df <- as.data.frame(dplyr::select(sample_sheet, name, location_name, date))

links <- lapply(sample_names, function(sample) {
  as.vector(lapply(reports, function(report) {
    paste0("<a href=", sample, report$suffix, ">", report$name, "</a>")
  }))
})

df$reports <- links

datatable(df, options = list(
  fixedColumns = TRUE,
  scrollY = 180,
  scrollX = TRUE,
  scroller = TRUE,
  dom = "Slfrtip"
))
```

# Discarded samples 

Prior visualization and regression analysis each sample gets a quality score
depending on proportion of covered reference genome and proportion of covered
signature mutation locations. Results from samples without sufficient coverage
measures (< `r mutation_coverage_threshold`%) are not included in the
visualizations or the linear regression calculations. 

```{r title_quality_score, results = 'asis'}
# table displaying bad samples which are not further inlcuded
# TODO refine this text
cat(
  "\n Table 1: Discarded samples not matching the provided sample",
  "quality scoring"
)
```

```{r table_ample_quality_score}
if (!(length(coverages_df) == 0)) {
  # TODO refine column names --> e.g "coverage in percent",
  bad_samples_df <- bad_samples_df %>% slice_head(n = 20)
  create_dt(bad_samples_df)
} else {
  cat("\n No coverage values found.")
}
```
